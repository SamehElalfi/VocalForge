{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: VocalForge[text] in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (0.0.5)\n",
      "Requirement already satisfied: numpy==1.23.2 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from VocalForge[text]) (1.23.2)\n",
      "Requirement already satisfied: natsort==8.2.0 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from VocalForge[text]) (8.2.0)\n",
      "Requirement already satisfied: tqdm==4.64.1 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from VocalForge[text]) (4.64.1)\n",
      "Requirement already satisfied: pydub in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from VocalForge[text]) (0.25.1)\n",
      "Requirement already satisfied: pandas==1.4.3 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from VocalForge[text]) (1.4.3)\n",
      "Requirement already satisfied: scipy==1.10.1 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from VocalForge[text]) (1.10.1)\n",
      "Requirement already satisfied: joblib==1.2.0 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from VocalForge[text]) (1.2.0)\n",
      "Requirement already satisfied: regex==2022.10.31 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from VocalForge[text]) (2022.10.31)\n",
      "Collecting openai-whisper\n",
      "  Using cached openai_whisper-20230314-py3-none-any.whl\n",
      "Collecting nemo-toolkit\n",
      "  Using cached nemo_toolkit-1.18.1-py3-none-any.whl (2.3 MB)\n",
      "Collecting ctc-segmentation\n",
      "  Using cached ctc_segmentation-1.7.4-cp38-cp38-linux_x86_64.whl\n",
      "Collecting whisper\n",
      "  Using cached whisper-1.1.10-py3-none-any.whl\n",
      "Collecting num2words==0.5.12\n",
      "  Using cached num2words-0.5.12-py3-none-any.whl (125 kB)\n",
      "Collecting nemo==4.5.5\n",
      "  Using cached NEMO-4.5.5-py36-none-any.whl (1.5 MB)\n",
      "Collecting nemo-text-processing\n",
      "  Using cached nemo_text_processing-0.1.7rc0-py3-none-any.whl (2.2 MB)\n",
      "Requirement already satisfied: yt-dlp in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from VocalForge[text]) (2023.3.4)\n",
      "Collecting drf-excel==2.3.0\n",
      "  Using cached drf_excel-2.3.0-py3-none-any.whl (13 kB)\n",
      "Collecting djangorestframework==3.14.0\n",
      "  Using cached djangorestframework-3.14.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting ldap3==2.9.1\n",
      "  Using cached ldap3-2.9.1-py2.py3-none-any.whl (432 kB)\n",
      "Collecting Pillow==9.5.0\n",
      "  Using cached Pillow-9.5.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "Collecting requests==2.28.2\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Collecting drf-flex-fields==1.0.2\n",
      "  Using cached drf_flex_fields-1.0.2-py3-none-any.whl\n",
      "Collecting cryptography==40.0.1\n",
      "  Using cached cryptography-40.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (3.7 MB)\n",
      "Collecting Django==3.2.19\n",
      "  Using cached Django-3.2.19-py3-none-any.whl (7.9 MB)\n",
      "Collecting django-auditlog==2.2.2\n",
      "  Using cached django_auditlog-2.2.2-py3-none-any.whl (28 kB)\n",
      "Collecting django-mptt==0.14.0\n",
      "  Using cached django_mptt-0.14.0-py3-none-any.whl (115 kB)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from nemo==4.5.5->VocalForge[text]) (2.8.2)\n",
      "Collecting pymodbus==3.2.2\n",
      "  Using cached pymodbus-3.2.2-py3-none-any.whl (166 kB)\n",
      "Collecting django-filter==23.1\n",
      "  Using cached django_filter-23.1-py3-none-any.whl (91 kB)\n",
      "Requirement already satisfied: pytz==2023.3 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from nemo==4.5.5->VocalForge[text]) (2023.3)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from num2words==0.5.12->VocalForge[text]) (0.6.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from cryptography==40.0.1->nemo==4.5.5->VocalForge[text]) (1.15.1)\n",
      "Collecting asgiref<4,>=3.3.2\n",
      "  Using cached asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
      "Collecting sqlparse>=0.2.2\n",
      "  Using cached sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "Collecting django-js-asset\n",
      "  Using cached django_js_asset-2.0.0-py3-none-any.whl (4.9 kB)\n",
      "Collecting openpyxl>=2.4\n",
      "  Using cached openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "Requirement already satisfied: pyasn1>=0.4.6 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from ldap3==2.9.1->nemo==4.5.5->VocalForge[text]) (0.5.0)\n",
      "Collecting setuptools<66.0.0\n",
      "  Using cached setuptools-65.7.0-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: six>=1.5 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from python-dateutil==2.8.2->nemo==4.5.5->VocalForge[text]) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from requests==2.28.2->nemo==4.5.5->VocalForge[text]) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from requests==2.28.2->nemo==4.5.5->VocalForge[text]) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from requests==2.28.2->nemo==4.5.5->VocalForge[text]) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from requests==2.28.2->nemo==4.5.5->VocalForge[text]) (1.26.16)\n",
      "Collecting Cython\n",
      "  Using cached Cython-0.29.35-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (2.0 MB)\n",
      "Collecting setuptools<66.0.0\n",
      "  Using cached setuptools-65.5.1-py3-none-any.whl (1.2 MB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.30.1-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cdifflib\n",
      "  Using cached cdifflib-1.2.6-cp38-cp38-linux_x86_64.whl\n",
      "Collecting jiwer>2.3.0\n",
      "  Using cached jiwer-3.0.1-py3-none-any.whl (21 kB)\n",
      "Collecting inflect\n",
      "  Using cached inflect-6.0.4-py3-none-any.whl (34 kB)\n",
      "Collecting wget\n",
      "  Using cached wget-3.2-py3-none-any.whl\n",
      "Collecting wrapt\n",
      "  Using cached wrapt-1.15.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "Collecting sacremoses>=0.0.43\n",
      "  Using cached sacremoses-0.0.53-py3-none-any.whl\n",
      "Collecting pynini==2.1.5\n",
      "  Using cached pynini-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161.5 MB)\n",
      "Requirement already satisfied: huggingface-hub in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from nemo-toolkit->VocalForge[text]) (0.15.1)\n",
      "Requirement already satisfied: scikit-learn in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from nemo-toolkit->VocalForge[text]) (1.2.2)\n",
      "Requirement already satisfied: ruamel.yaml in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from nemo-toolkit->VocalForge[text]) (0.17.28)\n",
      "Collecting onnx>=1.7.0\n",
      "  Using cached onnx-1.14.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
      "Requirement already satisfied: tensorboard in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from nemo-toolkit->VocalForge[text]) (2.13.0)\n",
      "Requirement already satisfied: torch in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from nemo-toolkit->VocalForge[text]) (1.11.0)\n",
      "Requirement already satisfied: numba in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from nemo-toolkit->VocalForge[text]) (0.57.0)\n",
      "Collecting text-unidecode\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Collecting triton==2.0.0\n",
      "  Using cached triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n",
      "Collecting ffmpeg-python==0.2.0\n",
      "  Using cached ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting more-itertools\n",
      "  Using cached more_itertools-9.1.0-py3-none-any.whl (54 kB)\n",
      "Collecting tiktoken==0.3.1\n",
      "  Using cached tiktoken-0.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Collecting future\n",
      "  Using cached future-0.18.3-py3-none-any.whl\n",
      "Collecting lit\n",
      "  Downloading lit-16.0.5.post0.tar.gz (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.1/138.1 kB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from triton==2.0.0->openai-whisper->VocalForge[text]) (3.12.1)\n",
      "Collecting cmake\n",
      "  Downloading cmake-3.26.4-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: brotli in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from yt-dlp->VocalForge[text]) (1.0.9)\n",
      "Requirement already satisfied: mutagen in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from yt-dlp->VocalForge[text]) (1.46.0)\n",
      "Requirement already satisfied: pycryptodomex in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from yt-dlp->VocalForge[text]) (3.18.0)\n",
      "Requirement already satisfied: websockets in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from yt-dlp->VocalForge[text]) (11.0.3)\n",
      "Collecting rapidfuzz==2.13.7\n",
      "  Using cached rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from jiwer>2.3.0->nemo-text-processing->VocalForge[text]) (8.1.3)\n",
      "Collecting protobuf>=3.20.2\n",
      "  Using cached protobuf-4.23.2-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from onnx>=1.7.0->nemo-toolkit->VocalForge[text]) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from huggingface-hub->nemo-toolkit->VocalForge[text]) (23.1)\n",
      "Requirement already satisfied: fsspec in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from huggingface-hub->nemo-toolkit->VocalForge[text]) (2023.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from huggingface-hub->nemo-toolkit->VocalForge[text]) (6.0)\n",
      "Collecting pydantic>=1.9.1\n",
      "  Downloading pydantic-1.10.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from numba->nemo-toolkit->VocalForge[text]) (6.6.0)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from numba->nemo-toolkit->VocalForge[text]) (0.40.1rc1)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from ruamel.yaml->nemo-toolkit->VocalForge[text]) (0.2.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from scikit-learn->nemo-toolkit->VocalForge[text]) (3.1.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from tensorboard->nemo-toolkit->VocalForge[text]) (2.19.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from tensorboard->nemo-toolkit->VocalForge[text]) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from tensorboard->nemo-toolkit->VocalForge[text]) (1.54.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from tensorboard->nemo-toolkit->VocalForge[text]) (2.3.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from tensorboard->nemo-toolkit->VocalForge[text]) (3.4.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from tensorboard->nemo-toolkit->VocalForge[text]) (0.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from tensorboard->nemo-toolkit->VocalForge[text]) (1.0.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from tensorboard->nemo-toolkit->VocalForge[text]) (0.38.4)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pycparser in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from cffi>=1.12->cryptography==40.0.1->nemo==4.5.5->VocalForge[text]) (2.21)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->nemo-toolkit->VocalForge[text]) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->nemo-toolkit->VocalForge[text]) (5.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->nemo-toolkit->VocalForge[text]) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->nemo-toolkit->VocalForge[text]) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from importlib-metadata->numba->nemo-toolkit->VocalForge[text]) (3.15.0)\n",
      "Collecting et-xmlfile\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard->nemo-toolkit->VocalForge[text]) (2.1.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->nemo-toolkit->VocalForge[text]) (3.2.2)\n",
      "Building wheels for collected packages: lit\n",
      "  Building wheel for lit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.5.post0-py3-none-any.whl size=88253 sha256=0ea6663ee9efc975a3f0056e0ad4b6c44a3654ca62869d8c7dedfcbb181fa955\n",
      "  Stored in directory: /home/rio/.cache/pip/wheels/8f/1f/ae/dac02ad52cca765f5f75b090964a3e71db5a2bc327fff49d0e\n",
      "Successfully built lit\n",
      "Installing collected packages: wget, tokenizers, text-unidecode, safetensors, lit, drf-flex-fields, cmake, wrapt, whisper, sqlparse, setuptools, sacremoses, requests, rapidfuzz, pydantic, protobuf, Pillow, num2words, more-itertools, ldap3, future, et-xmlfile, Cython, cdifflib, asgiref, triton, tiktoken, pynini, pymodbus, openpyxl, onnx, jiwer, inflect, ffmpeg-python, Django, ctc-segmentation, cryptography, transformers, openai-whisper, djangorestframework, django-js-asset, django-filter, django-auditlog, nemo-text-processing, drf-excel, django-mptt, nemo-toolkit, nemo\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 67.8.0\n",
      "    Uninstalling setuptools-67.8.0:\n",
      "      Successfully uninstalled setuptools-67.8.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.29.0\n",
      "    Uninstalling requests-2.29.0:\n",
      "      Successfully uninstalled requests-2.29.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 9.4.0\n",
      "    Uninstalling Pillow-9.4.0:\n",
      "      Successfully uninstalled Pillow-9.4.0\n",
      "  Attempting uninstall: cryptography\n",
      "    Found existing installation: cryptography 39.0.1\n",
      "    Uninstalling cryptography-39.0.1:\n",
      "      Successfully uninstalled cryptography-39.0.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytorch-lightning 1.6.5 requires protobuf<=3.20.1, but you have protobuf 4.23.2 which is incompatible.\n",
      "pyopenssl 23.0.0 requires cryptography<40,>=38.0.0, but you have cryptography 40.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Cython-0.29.35 Django-3.2.19 Pillow-9.5.0 asgiref-3.7.2 cdifflib-1.2.6 cmake-3.26.4 cryptography-40.0.1 ctc-segmentation-1.7.4 django-auditlog-2.2.2 django-filter-23.1 django-js-asset-2.0.0 django-mptt-0.14.0 djangorestframework-3.14.0 drf-excel-2.3.0 drf-flex-fields-1.0.2 et-xmlfile-1.1.0 ffmpeg-python-0.2.0 future-0.18.3 inflect-6.0.4 jiwer-3.0.1 ldap3-2.9.1 lit-16.0.5.post0 more-itertools-9.1.0 nemo-4.5.5 nemo-text-processing-0.1.7rc0 nemo-toolkit-1.18.1 num2words-0.5.12 onnx-1.14.0 openai-whisper-20230314 openpyxl-3.1.2 protobuf-4.23.2 pydantic-1.10.9 pymodbus-3.2.2 pynini-2.1.5 rapidfuzz-2.13.7 requests-2.28.2 sacremoses-0.0.53 safetensors-0.3.1 setuptools-65.5.1 sqlparse-0.4.4 text-unidecode-1.3 tiktoken-0.3.1 tokenizers-0.13.3 transformers-4.30.1 triton-2.0.0 wget-3.2 whisper-1.1.10 wrapt-1.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install VocalForge['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_path = os.getcwd()\n",
    "# print(root_path)\n",
    "os.mkdir(os.path.join(root_path, 'work'))\n",
    "os.mkdir(os.path.join(root_path, 'work/text'))\n",
    "work_path = os.path.join(root_path, 'work/text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VocalForge.text.text_utils import create_core_folders\n",
    "folders = ['input_audio', 'transcription', 'processed', 'segments', 'sliced_audio', 'dataset']\n",
    "create_core_folders(folders, work_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rio/Desktop/PersonCreator/voice/curate/work/text/../audio/exported\n"
     ]
    }
   ],
   "source": [
    "print(os.path.join(work_path, '..', 'audio/exported'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-11 18:07:04 optimizers:54] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2023-06-11 18:07:04 experimental:27] Module <class 'nemo.collections.asr.modules.audio_modules.SpectrogramToMultichannelFeatures'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2023-06-11 18:07:05 nemo_logging:349] /home/rio/anaconda3/envs/VocalForge/lib/python3.8/site-packages/whisper/timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "      def backtrace(trace: np.ndarray):\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from VocalForge.text.transcribe import Transcribe\n",
    "\n",
    "transcribe = Transcribe(\n",
    "    raw_dir= os.path.join(work_path, 'input_audio'),\n",
    "    out_dir= os.path.join(work_path, 'transcription'),\n",
    "    prompt = \"uh, um, I...I think that what, what you're saying is terrible, mhm. Ya'know?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribe.run_trancription()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VocalForge.text.normalize_text import NormalizeText\n",
    "\n",
    "normalize = NormalizeText(\n",
    "    input_dir= os.path.join(work_path, 'transcription'),\n",
    "    out_dir= os.path.join(work_path, 'processed'),\n",
    "    audio_dir= os.path.join(work_path, 'input_audio'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rio/Desktop/PersonCreator/voice/curate/work/text/processed\n",
      "Splitting text in /home/rio/Desktop/PersonCreator/voice/curate/work/text/transcription/DATA3.txt into sentences.\n",
      "Using NeMo normalization tool...\n",
      "Created /home/rio/Desktop/PersonCreator/voice/curate/en_grammars/en_tn_post_processing.far\n",
      "Created /home/rio/Desktop/PersonCreator/voice/curate/en_grammars/en_tn_True_deterministic_cased__tokenize.far\n",
      "Created /home/rio/Desktop/PersonCreator/voice/curate/en_grammars/en_tn_True_deterministic_verbalizer.far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:02<00:00, 40.00it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 53.43it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 52.40it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 52.91it/s]\n",
      "100%|██████████| 66/66 [00:01<00:00, 40.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rio/Desktop/PersonCreator/voice/curate/work/text/processed/DATA3/DATA3\n",
      "/home/rio/Desktop/PersonCreator/voice/curate/work/text/processed/DATA3/DATA3_with_punct_normalized\n",
      "/home/rio/Desktop/PersonCreator/voice/curate/work/text/processed/DATA3/DATA3_with_punct\n",
      "Splitting text in /home/rio/Desktop/PersonCreator/voice/curate/work/text/transcription/DATA9.txt into sentences.\n",
      "Using NeMo normalization tool...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 69.08it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 88.15it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 101.96it/s]\n",
      "100%|██████████| 46/46 [00:00<00:00, 93.00it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rio/Desktop/PersonCreator/voice/curate/work/text/processed/DATA9/DATA9\n",
      "/home/rio/Desktop/PersonCreator/voice/curate/work/text/processed/DATA9/DATA9_with_punct_normalized\n",
      "/home/rio/Desktop/PersonCreator/voice/curate/work/text/processed/DATA9/DATA9_with_punct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "normalize.run_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-11 21:16:29 mixins:170] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2023-06-11 21:16:29 modelPT:161] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2023-06-11 21:16:29 modelPT:168] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2023-06-11 21:16:29 modelPT:174] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2023-06-11 21:16:29 features:287] PADDING: 16\n",
      "[NeMo I 2023-06-11 21:16:31 audio_preprocessing:517] Numba CUDA SpecAugment kernel is being used\n",
      "[NeMo I 2023-06-11 21:16:33 save_restore_connector:249] Model EncDecCTCModelBPE was successfully restored from /home/rio/.cache/huggingface/hub/models--nvidia--stt_en_citrinet_1024_gamma_0_25/snapshots/9d4f0a71ee143a5c3a67e4ebde19e2ba92b87399/stt_en_citrinet_1024_gamma_0_25.nemo.\n"
     ]
    }
   ],
   "source": [
    "from VocalForge.text.segment import Segment\n",
    "import os\n",
    "segment = Segment(\n",
    "    input_dir= os.path.join(work_path, 'processed'),\n",
    "    output_dir= os.path.join(work_path, 'segments')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmenting /home/rio/Desktop/PersonCreator/voice/curate/work/text/processed/DATA3/DATA3.wav...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eae104fd9e54280be5355ff19fea679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 466/466 [00:00<00:00, 12133.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average segmentation loss: -0.5531351084339613\n",
      "segmenting /home/rio/Desktop/PersonCreator/voice/curate/work/text/processed/DATA9/DATA9.wav...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305d9d5bf4e3455db8ff85578bbb6214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 346/346 [00:00<00:00, 41399.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average segmentation loss: -0.8811675371399106\n",
      "median loss: -0.7171513227869359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "segment.run_segmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "import IPython.display as ipd\n",
    "threshold = 0.75\n",
    "\n",
    "def test_offset_padding(alignment_file: str):\n",
    "    offset = 0\n",
    "    padding = 0\n",
    "    if not os.path.exists(alignment_file):\n",
    "        raise ValueError(f\"{alignment_file} not found\")\n",
    "    # read the segments, note the first line contains the path to the original audio\n",
    "    print(f\"Reading {alignment_file}\")\n",
    "    with open(alignment_file, \"r\") as f:\n",
    "        \n",
    "        sample = [next(f) for _ in range(10)]\n",
    "        offset = input('Input offset (type \"stop\" to end): ')\n",
    "        padding = input('Input padding: ')\n",
    "        padding = float(padding)\n",
    "        \n",
    "        while True:\n",
    "            print(f\"offset: {offset}, padding: {padding}\")\n",
    "            for line in sample:\n",
    "                line = line.split(\"|\")\n",
    "                if len(line) == 1:\n",
    "                    audio_file = line[0].strip()\n",
    "                    continue\n",
    "                text = line[2]\n",
    "                line = line[0].split()\n",
    "                sampling_rate, signal = wav.read(audio_file)\n",
    "                if float(line[2]) < -threshold:\n",
    "                    continue\n",
    "                segment = [float(line[0]) + float(offset) + padding, float(line[1]) + float(offset) - padding]\n",
    "                if float(line[0]) + float(offset) < 0:\n",
    "                    segment[0] = 0\n",
    "                st, end = segment\n",
    "                audio = signal[round(st * sampling_rate) : round(end * sampling_rate)]\n",
    "                print(f\"loss: {line[2]}\")\n",
    "                print(f'sample text: {text}')\n",
    "                ipd.display(ipd.Audio(audio, rate=sampling_rate))\n",
    "            previous_offset = offset\n",
    "            offset = input('Input offset (type \"stop\" to end): ')\n",
    "            if offset == 'stop':\n",
    "                offset = previous_offset\n",
    "                print(f\"final values for {alignment_file}: offset: {offset}, padding: {padding}\") \n",
    "                break\n",
    "            padding = float(input('Input padding: '))\n",
    "        return offset, padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = []\n",
    "paddings = []\n",
    "from VocalForge.text.text_utils import get_files\n",
    "segment_dir = os.path.join(work_path, 'segments')\n",
    "for file in get_files(segment_dir, '.txt'):\n",
    "    file_dir = os.path.join(segment_dir, file)\n",
    "    offset, padding = test_offset_padding(alignment_file=file_dir)\n",
    "    offsets.append(offset)\n",
    "    paddings.append(padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rio/Desktop/PersonCreator/voice/curate/work/text/segments\n"
     ]
    }
   ],
   "source": [
    "from VocalForge.text.split_audio import SplitAudio\n",
    "threshold = 0.6\n",
    "split = SplitAudio(\n",
    "    input_dir=segment_dir,\n",
    "    output_dir=os.path.join(work_path, 'sliced_audio'),\n",
    "    max_duration=20,\n",
    "    threshold=threshold,\n",
    "    offsets=offsets,\n",
    "    paddings=paddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original duration  : 31min\n",
      "High score segments: 23min (73%)\n",
      "Low score segments : 8min (25%)\n",
      "Original duration  : 13min\n",
      "High score segments: 9min (66%)\n",
      "Low score segments : 5min (36%)\n"
     ]
    }
   ],
   "source": [
    "split.run_slicing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VocalForge.text.create_dataset import GenerateDataset\n",
    "dataset = GenerateDataset(\n",
    "    segment_dir=segment_dir,\n",
    "    sliced_aud_dir=os.path.join(work_path, 'sliced_audio'),\n",
    "    output_dir=os.path.join(work_path, 'dataset'),\n",
    "    threshold=threshold,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has been created!\n"
     ]
    }
   ],
   "source": [
    "dataset.run_dataset_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rio/Desktop/PersonCreator/voice/curate/work/text/dataset\n",
      "['DATA3_0363.wav', 'DATA9_0205.wav', 'DATA3_0236.wav', 'DATA9_0337.wav', 'DATA9_0309.wav', 'DATA3_0383.wav', 'DATA9_0183.wav', 'DATA3_0061.wav', 'DATA3_0126.wav', 'DATA9_0181.wav', 'DATA3_0314.wav', 'DATA3_0398.wav', 'DATA9_0284.wav', 'DATA9_0270.wav', 'DATA3_0030.wav', 'DATA3_0294.wav', 'DATA9_0215.wav', 'DATA3_0185.wav', 'DATA3_0371.wav', 'DATA3_0211.wav', 'DATA9_0330.wav', 'DATA3_0193.wav', 'DATA9_0225.wav', 'DATA9_0016.wav', 'DATA3_0137.wav', 'DATA3_0303.wav', 'DATA9_0140.wav', 'DATA9_0300.wav', 'DATA9_0117.wav', 'DATA3_0138.wav', 'DATA9_0075.wav', 'DATA3_0206.wav', 'DATA9_0208.wav', 'DATA9_0251.wav', 'DATA9_0224.wav', 'DATA3_0067.wav', 'DATA3_0264.wav', 'DATA9_0013.wav', 'DATA9_0272.wav', 'DATA9_0253.wav', 'DATA9_0301.wav', 'DATA3_0275.wav', 'DATA9_0012.wav', 'DATA3_0057.wav', 'DATA3_0123.wav', 'DATA9_0277.wav', 'DATA3_0037.wav', 'DATA9_0188.wav']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "bad_files = []\n",
    "dataset_dir = os.path.join(work_path, 'dataset')\n",
    "print(dataset_dir)\n",
    "for file in os.listdir(dataset_dir+'/wavs/'):\n",
    "    #if file is below 100kb remove it and append it to the list\n",
    "    if os.stat(dataset_dir +'/wavs/'+file).st_size < 50000:\n",
    "        bad_files.append(file)\n",
    "print(bad_files)\n",
    "\n",
    "df = pd.read_csv(dataset_dir+'/metadata.csv', sep='|', on_bad_lines='skip')\n",
    "for index, row in df.iterrows():\n",
    "    if row[0]+'.wav' in bad_files:\n",
    "        df.drop(index, inplace=True)\n",
    "        os.remove(dataset_dir + '/wavs/' + row[0]+'.wav')\n",
    "df.to_csv(dataset_dir+'/metadata.csv', sep='|', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_dir+'/metadata.csv', sep='|', on_bad_lines='skip')\n",
    "wav_files = os.listdir(dataset_dir + '/wavs/')\n",
    "good_files = []\n",
    "for index, row in df.iterrows():\n",
    "    good_files.append(row[0]+'.wav')\n",
    "\n",
    "for file in wav_files:\n",
    "    if file not in good_files:\n",
    "        os.remove(dataset_dir + '/wavs/' + file)\n",
    "        print(file + ' removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA3_0003\n",
      "DATA3_0006\n",
      "DATA3_0010\n",
      "DATA3_0011\n",
      "DATA3_0012\n",
      "DATA3_0013\n",
      "DATA3_0014\n",
      "DATA3_0015\n",
      "DATA3_0016\n",
      "DATA3_0017\n",
      "DATA3_0018\n",
      "DATA3_0019\n",
      "DATA3_0020\n",
      "DATA3_0021\n",
      "DATA3_0022\n",
      "DATA3_0023\n",
      "DATA3_0025\n",
      "DATA3_0026\n",
      "DATA3_0027\n",
      "DATA3_0028\n",
      "DATA3_0029\n",
      "DATA3_0031\n",
      "DATA3_0032\n",
      "DATA3_0033\n",
      "DATA3_0034\n",
      "DATA3_0035\n",
      "DATA3_0038\n",
      "DATA3_0040\n",
      "DATA3_0041\n",
      "DATA3_0042\n",
      "DATA3_0043\n",
      "DATA3_0044\n",
      "DATA3_0045\n",
      "DATA3_0047\n",
      "DATA3_0048\n",
      "DATA3_0049\n",
      "DATA3_0050\n",
      "DATA3_0051\n",
      "DATA3_0052\n",
      "DATA3_0053\n",
      "DATA3_0054\n",
      "DATA3_0059\n",
      "DATA3_0060\n",
      "DATA3_0062\n",
      "DATA3_0063\n",
      "DATA3_0064\n",
      "DATA3_0065\n",
      "DATA3_0066\n",
      "DATA3_0068\n",
      "DATA3_0069\n",
      "DATA3_0070\n",
      "DATA3_0071\n",
      "DATA3_0075\n",
      "DATA3_0076\n",
      "DATA3_0077\n",
      "DATA3_0078\n",
      "DATA3_0079\n",
      "DATA3_0080\n",
      "DATA3_0081\n",
      "DATA3_0082\n",
      "DATA3_0083\n",
      "DATA3_0084\n",
      "DATA3_0085\n",
      "DATA3_0086\n",
      "DATA3_0087\n",
      "DATA3_0088\n",
      "DATA3_0089\n",
      "DATA3_0090\n",
      "DATA3_0095\n",
      "DATA3_0096\n",
      "DATA3_0097\n",
      "DATA3_0098\n",
      "DATA3_0099\n",
      "DATA3_0100\n",
      "DATA3_0101\n",
      "DATA3_0102\n",
      "DATA3_0103\n",
      "DATA3_0105\n",
      "DATA3_0106\n",
      "DATA3_0107\n",
      "DATA3_0108\n",
      "DATA3_0109\n",
      "DATA3_0110\n",
      "DATA3_0111\n",
      "DATA3_0112\n",
      "DATA3_0113\n",
      "DATA3_0114\n",
      "DATA3_0115\n",
      "DATA3_0116\n",
      "DATA3_0118\n",
      "DATA3_0119\n",
      "DATA3_0120\n",
      "DATA3_0121\n",
      "DATA3_0122\n",
      "DATA3_0124\n",
      "DATA3_0125\n",
      "DATA3_0127\n",
      "DATA3_0128\n",
      "DATA3_0129\n",
      "DATA3_0130\n",
      "DATA3_0131\n",
      "DATA3_0133\n",
      "DATA3_0136\n",
      "DATA3_0142\n",
      "DATA3_0143\n",
      "DATA3_0144\n",
      "DATA3_0145\n",
      "DATA3_0146\n",
      "DATA3_0148\n",
      "DATA3_0149\n",
      "DATA3_0150\n",
      "DATA3_0151\n",
      "DATA3_0152\n",
      "DATA3_0153\n",
      "DATA3_0154\n",
      "DATA3_0155\n",
      "DATA3_0156\n",
      "DATA3_0157\n",
      "DATA3_0158\n",
      "DATA3_0159\n",
      "DATA3_0160\n",
      "DATA3_0161\n",
      "DATA3_0162\n",
      "DATA3_0163\n",
      "DATA3_0164\n",
      "DATA3_0165\n",
      "DATA3_0166\n",
      "DATA3_0167\n",
      "DATA3_0170\n",
      "DATA3_0171\n",
      "DATA3_0174\n",
      "DATA3_0175\n",
      "DATA3_0179\n",
      "DATA3_0180\n",
      "DATA3_0181\n",
      "DATA3_0183\n",
      "DATA3_0184\n",
      "DATA3_0186\n",
      "DATA3_0188\n",
      "DATA3_0189\n",
      "DATA3_0190\n",
      "DATA3_0191\n",
      "DATA3_0192\n",
      "DATA3_0194\n",
      "DATA3_0195\n",
      "DATA3_0196\n",
      "DATA3_0198\n",
      "DATA3_0199\n",
      "DATA3_0200\n",
      "DATA3_0201\n",
      "DATA3_0202\n",
      "DATA3_0204\n",
      "DATA3_0205\n",
      "DATA3_0208\n",
      "DATA3_0209\n",
      "DATA3_0210\n",
      "DATA3_0212\n",
      "DATA3_0216\n",
      "DATA3_0217\n",
      "DATA3_0220\n",
      "DATA3_0224\n",
      "DATA3_0225\n",
      "DATA3_0226\n",
      "DATA3_0227\n",
      "DATA3_0228\n",
      "DATA3_0229\n",
      "DATA3_0230\n",
      "DATA3_0231\n",
      "DATA3_0232\n",
      "DATA3_0233\n",
      "DATA3_0234\n",
      "DATA3_0235\n",
      "DATA3_0238\n",
      "DATA3_0239\n",
      "DATA3_0241\n",
      "DATA3_0242\n",
      "DATA3_0243\n",
      "DATA3_0245\n",
      "DATA3_0247\n",
      "DATA3_0249\n",
      "DATA3_0250\n",
      "DATA3_0251\n",
      "DATA3_0252\n",
      "DATA3_0253\n",
      "DATA3_0254\n",
      "DATA3_0256\n",
      "DATA3_0257\n",
      "DATA3_0258\n",
      "DATA3_0260\n",
      "DATA3_0262\n",
      "DATA3_0263\n",
      "DATA3_0265\n",
      "DATA3_0266\n",
      "DATA3_0267\n",
      "DATA3_0268\n",
      "DATA3_0269\n",
      "DATA3_0271\n",
      "DATA3_0272\n",
      "DATA3_0273\n",
      "DATA3_0274\n",
      "DATA3_0276\n",
      "DATA3_0277\n",
      "DATA3_0281\n",
      "DATA3_0283\n",
      "DATA3_0284\n",
      "DATA3_0285\n",
      "DATA3_0287\n",
      "DATA3_0288\n",
      "DATA3_0289\n",
      "DATA3_0290\n",
      "DATA3_0291\n",
      "DATA3_0292\n",
      "DATA3_0293\n",
      "DATA3_0295\n",
      "DATA3_0296\n",
      "DATA3_0297\n",
      "DATA3_0299\n",
      "DATA3_0300\n",
      "DATA3_0301\n",
      "DATA3_0302\n",
      "DATA3_0304\n",
      "DATA3_0305\n",
      "DATA3_0306\n",
      "DATA3_0309\n",
      "DATA3_0310\n",
      "DATA3_0311\n",
      "DATA3_0312\n",
      "DATA3_0318\n",
      "DATA3_0319\n",
      "DATA3_0320\n",
      "DATA3_0321\n",
      "DATA3_0323\n",
      "DATA3_0325\n",
      "DATA3_0326\n",
      "DATA3_0327\n",
      "DATA3_0328\n",
      "DATA3_0330\n",
      "DATA3_0331\n",
      "DATA3_0332\n",
      "DATA3_0333\n",
      "DATA3_0334\n",
      "DATA3_0338\n",
      "DATA3_0340\n",
      "DATA3_0341\n",
      "DATA3_0342\n",
      "DATA3_0343\n",
      "DATA3_0344\n",
      "DATA3_0345\n",
      "DATA3_0346\n",
      "DATA3_0347\n",
      "DATA3_0349\n",
      "DATA3_0350\n",
      "DATA3_0351\n",
      "DATA3_0352\n",
      "DATA3_0353\n",
      "DATA3_0354\n",
      "DATA3_0355\n",
      "DATA3_0356\n",
      "DATA3_0357\n",
      "DATA3_0358\n",
      "DATA3_0359\n",
      "DATA3_0360\n",
      "DATA3_0361\n",
      "DATA3_0362\n",
      "DATA3_0364\n",
      "DATA3_0365\n",
      "DATA3_0366\n",
      "DATA3_0367\n",
      "DATA3_0368\n",
      "DATA3_0373\n",
      "DATA3_0374\n",
      "DATA3_0375\n",
      "DATA3_0376\n",
      "DATA3_0377\n",
      "DATA3_0378\n",
      "DATA3_0382\n",
      "DATA3_0384\n",
      "DATA3_0386\n",
      "DATA3_0387\n",
      "DATA3_0388\n",
      "DATA3_0389\n",
      "DATA3_0390\n",
      "DATA3_0391\n",
      "DATA3_0393\n",
      "DATA3_0394\n",
      "DATA3_0395\n",
      "DATA3_0396\n",
      "DATA3_0397\n",
      "DATA3_0399\n",
      "DATA3_0400\n",
      "DATA3_0401\n",
      "DATA3_0403\n",
      "DATA3_0408\n",
      "DATA3_0411\n",
      "DATA3_0412\n",
      "DATA3_0413\n",
      "DATA3_0417\n",
      "DATA3_0418\n",
      "DATA3_0419\n",
      "DATA3_0420\n",
      "DATA3_0421\n",
      "DATA3_0422\n",
      "DATA3_0428\n",
      "DATA3_0434\n",
      "DATA3_0437\n",
      "DATA3_0438\n",
      "DATA3_0439\n",
      "DATA3_0440\n",
      "DATA3_0444\n",
      "DATA3_0445\n",
      "DATA3_0446\n",
      "DATA3_0447\n",
      "DATA3_0448\n",
      "DATA3_0449\n",
      "DATA3_0450\n",
      "DATA3_0451\n",
      "DATA3_0452\n",
      "DATA3_0453\n",
      "DATA3_0454\n",
      "DATA3_0456\n",
      "DATA3_0457\n",
      "DATA3_0458\n",
      "DATA3_0459\n",
      "DATA3_0460\n",
      "DATA3_0461\n",
      "DATA3_0462\n",
      "DATA3_0463\n",
      "DATA3_0465\n",
      "DATA9_0003\n",
      "DATA9_0004\n",
      "DATA9_0010\n",
      "DATA9_0011\n",
      "DATA9_0018\n",
      "DATA9_0019\n",
      "DATA9_0020\n",
      "DATA9_0021\n",
      "DATA9_0024\n",
      "DATA9_0025\n",
      "DATA9_0026\n",
      "DATA9_0027\n",
      "DATA9_0028\n",
      "DATA9_0030\n",
      "DATA9_0031\n",
      "DATA9_0032\n",
      "DATA9_0037\n",
      "DATA9_0038\n",
      "DATA9_0039\n",
      "DATA9_0040\n",
      "DATA9_0044\n",
      "DATA9_0046\n",
      "DATA9_0048\n",
      "DATA9_0049\n",
      "DATA9_0051\n",
      "DATA9_0052\n",
      "DATA9_0053\n",
      "DATA9_0056\n",
      "DATA9_0057\n",
      "DATA9_0059\n",
      "DATA9_0060\n",
      "DATA9_0061\n",
      "DATA9_0062\n",
      "DATA9_0064\n",
      "DATA9_0066\n",
      "DATA9_0068\n",
      "DATA9_0069\n",
      "DATA9_0070\n",
      "DATA9_0071\n",
      "DATA9_0072\n",
      "DATA9_0073\n",
      "DATA9_0079\n",
      "DATA9_0080\n",
      "DATA9_0081\n",
      "DATA9_0082\n",
      "DATA9_0083\n",
      "DATA9_0084\n",
      "DATA9_0085\n",
      "DATA9_0089\n",
      "DATA9_0093\n",
      "DATA9_0096\n",
      "DATA9_0097\n",
      "DATA9_0098\n",
      "DATA9_0118\n",
      "DATA9_0119\n",
      "DATA9_0120\n",
      "DATA9_0121\n",
      "DATA9_0122\n",
      "DATA9_0123\n",
      "DATA9_0124\n",
      "DATA9_0129\n",
      "DATA9_0131\n",
      "DATA9_0133\n",
      "DATA9_0134\n",
      "DATA9_0135\n",
      "DATA9_0136\n",
      "DATA9_0137\n",
      "DATA9_0138\n",
      "DATA9_0141\n",
      "DATA9_0142\n",
      "DATA9_0144\n",
      "DATA9_0145\n",
      "DATA9_0146\n",
      "DATA9_0147\n",
      "DATA9_0153\n",
      "DATA9_0155\n",
      "DATA9_0156\n",
      "DATA9_0157\n",
      "DATA9_0158\n",
      "DATA9_0164\n",
      "DATA9_0165\n",
      "DATA9_0167\n",
      "DATA9_0168\n",
      "DATA9_0169\n",
      "DATA9_0170\n",
      "DATA9_0171\n",
      "DATA9_0174\n",
      "DATA9_0175\n",
      "DATA9_0180\n",
      "DATA9_0182\n",
      "DATA9_0185\n",
      "DATA9_0186\n",
      "DATA9_0187\n",
      "DATA9_0190\n",
      "DATA9_0191\n",
      "DATA9_0192\n",
      "DATA9_0193\n",
      "DATA9_0194\n",
      "DATA9_0195\n",
      "DATA9_0196\n",
      "DATA9_0197\n",
      "DATA9_0199\n",
      "DATA9_0202\n",
      "DATA9_0203\n",
      "DATA9_0204\n",
      "DATA9_0206\n",
      "DATA9_0207\n",
      "DATA9_0209\n",
      "DATA9_0210\n",
      "DATA9_0211\n",
      "DATA9_0212\n",
      "DATA9_0213\n",
      "DATA9_0214\n",
      "DATA9_0218\n",
      "DATA9_0219\n",
      "DATA9_0221\n",
      "DATA9_0222\n",
      "DATA9_0226\n",
      "DATA9_0227\n",
      "DATA9_0228\n",
      "DATA9_0229\n",
      "DATA9_0230\n",
      "DATA9_0231\n",
      "DATA9_0232\n",
      "DATA9_0233\n",
      "DATA9_0235\n",
      "DATA9_0236\n",
      "DATA9_0237\n",
      "DATA9_0238\n",
      "DATA9_0239\n",
      "DATA9_0241\n",
      "DATA9_0246\n",
      "DATA9_0247\n",
      "DATA9_0249\n",
      "DATA9_0250\n",
      "DATA9_0254\n",
      "DATA9_0256\n",
      "DATA9_0267\n",
      "DATA9_0268\n",
      "DATA9_0271\n",
      "DATA9_0273\n",
      "DATA9_0274\n",
      "DATA9_0275\n",
      "DATA9_0276\n",
      "DATA9_0279\n",
      "DATA9_0280\n",
      "DATA9_0281\n",
      "DATA9_0282\n",
      "DATA9_0283\n",
      "DATA9_0286\n",
      "DATA9_0287\n",
      "DATA9_0288\n",
      "DATA9_0289\n",
      "DATA9_0290\n",
      "DATA9_0291\n",
      "DATA9_0294\n",
      "DATA9_0295\n",
      "DATA9_0296\n",
      "DATA9_0297\n",
      "DATA9_0298\n",
      "DATA9_0299\n",
      "DATA9_0303\n",
      "DATA9_0304\n",
      "DATA9_0305\n",
      "DATA9_0307\n",
      "DATA9_0308\n",
      "DATA9_0310\n",
      "DATA9_0314\n",
      "DATA9_0317\n",
      "DATA9_0318\n",
      "DATA9_0319\n",
      "DATA9_0321\n",
      "DATA9_0322\n",
      "DATA9_0323\n",
      "DATA9_0324\n",
      "DATA9_0326\n",
      "DATA9_0327\n",
      "DATA9_0331\n",
      "DATA9_0332\n",
      "DATA9_0333\n",
      "DATA9_0334\n",
      "DATA9_0335\n",
      "DATA9_0336\n",
      "DATA9_0339\n",
      "DATA9_0340\n",
      "DATA9_0341\n",
      "DATA9_0342\n",
      "DATA9_0343\n",
      "DATA9_0344\n",
      "DATA9_0345\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "metadata = []\n",
    "wav_files = os.listdir(dataset_dir + '/wavs/')\n",
    "df = pd.read_csv(dataset_dir+'/metadata.csv', sep='|', on_bad_lines='skip')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(row[0])\n",
    "    if row[0]+'.wav' not in wav_files:\n",
    "        df.drop(index, inplace=True)\n",
    "        print(row[0])\n",
    "\n",
    "df.to_csv(dataset_dir+'/metadata.csv', sep='|', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VocalForge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
